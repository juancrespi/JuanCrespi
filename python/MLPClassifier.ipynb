{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import load_files\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk import pos_tag\n",
    "from collections import Counter \n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from sklearn.naive_bayes import BernoulliNB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  tweet_id                                            content  \\\n",
      "0      1240732695413395456  Any company that continues to deny their worke...   \n",
      "1      1240732695459696642  The same Tolu Ogunlesi that insisted that Mr J...   \n",
      "2      1240732695522664454  @pattonoswalt @AlanTudyk He can't pronounce co...   \n",
      "3      1240732695644291073                 Aqui risking the corona en el work   \n",
      "4      1240732695778324480  Day 5: We have rediscovered farming https://t....   \n",
      "...                    ...                                                ...   \n",
      "19995  1240863708219392001  this manâ€™s piss could stop corona https://t.co...   \n",
      "19996  1240863708290510849  #SocialDistancing #CoronaVirus#covid19#corona ...   \n",
      "19997  1240863708588335104  There was a nasty flu that went round in Decem...   \n",
      "19998  1240863708743487490  @YBRAP We will still be great even without the...   \n",
      "19999  1240863708882046976  My housemate went for a walk and has been coug...   \n",
      "\n",
      "       sentiment polarity  \n",
      "0      -0.238095      NEG  \n",
      "1       0.000000      NEU  \n",
      "2       0.000000      NEU  \n",
      "3       0.000000      NEU  \n",
      "4       0.000000      NEU  \n",
      "...          ...      ...  \n",
      "19995   0.000000      NEU  \n",
      "19996   0.000000      NEU  \n",
      "19997  -0.352857      NEG  \n",
      "19998   0.800000      POS  \n",
      "19999   0.000000      NEU  \n",
      "\n",
      "[20000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "url_test = \"datasets/corona_tweets_extracted.csv\"\n",
    "df_test_1 = pd.read_csv(url_test)\n",
    "df_test = df_test_1[35000:55000].reset_index(drop=True)\n",
    "print(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 tweet_id                                            content  \\\n",
      "0     1241623065756413957  @JoeBiden Bernie has raised over 2 million dol...   \n",
      "1     1241623065785581569  When this corona shit is over please invite me...   \n",
      "2     1241623065819148290         Corona virus sefty https://t.co/O7y0CP4BAS   \n",
      "3     1241623065827524608  Money spent on Son/Daughter marriage by :-\\n\\n...   \n",
      "4     1241623066213380098  #WhoCanSave_The_World\\n\\nIf you want to avoid ...   \n",
      "...                   ...                                                ...   \n",
      "9995  1241807261808254976  A Manipuri girl at Vijay Nagar, Delhi was spat...   \n",
      "9996  1241807261951053827  When this corona shit is over please invite me...   \n",
      "9997  1241807262013747200  now THIS is what I call high fashion https://t...   \n",
      "9998  1241807262076690432  Foolish people of Indore celebration corona fe...   \n",
      "9999  1241807262123020288  I got corona and an Std just from watching thi...   \n",
      "\n",
      "      sentiment         location coordinates                 date  \n",
      "0             0              NaN         NaN  2020-03-22 07:09:41  \n",
      "1          -0.1  California, USA         NaN  2020-03-22 07:09:41  \n",
      "2             0              NaN         NaN  2020-03-22 07:09:41  \n",
      "3          -0.1              NaN         NaN  2020-03-22 07:09:41  \n",
      "4            -1              NaN         NaN  2020-03-22 07:09:41  \n",
      "...         ...              ...         ...                  ...  \n",
      "9995 -0.0333333              NaN         NaN  2020-03-22 19:21:37  \n",
      "9996       -0.1              NaN         NaN  2020-03-22 19:21:37  \n",
      "9997       0.16              NaN         NaN  2020-03-22 19:21:37  \n",
      "9998          0              NaN         NaN  2020-03-22 19:21:37  \n",
      "9999         -1     Florida, USA         NaN  2020-03-22 19:21:37  \n",
      "\n",
      "[10000 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34722\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (0,2) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "url_test2 = \"DataSets/group_datasets/corona_tweets_extracted_loc_date_test.csv\"\n",
    "df_test2 = pd.read_csv(url_test2)\n",
    "df_test3 = df_test2[35000:45000].reset_index(drop=True)\n",
    "print(df_test3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 tweet_id                                            content  \\\n",
      "0     1240732695413395456  Any company that continues to deny their worke...   \n",
      "1     1240732695459696642  The same Tolu Ogunlesi that insisted that Mr J...   \n",
      "2     1240732695522664454  @pattonoswalt @AlanTudyk He can't pronounce co...   \n",
      "3     1240732695644291073                 Aqui risking the corona en el work   \n",
      "4     1240732695778324480  Day 5: We have rediscovered farming https://t....   \n",
      "...                   ...                                                ...   \n",
      "1995  1240732978357166081                           @yeeyi_1 I blame Corona.   \n",
      "1996  1240732978415878145  hereâ€™s a deleted scene from TWDâ€™s special on c...   \n",
      "1997  1240732978441007112  ðŸ˜‚ðŸ˜‚ðŸ˜‚ I love my country, but how did we get here...   \n",
      "1998  1240732978487144449  When this Corona shit passes we have to promis...   \n",
      "1999  1240732978529153025                  Dit mens. https://t.co/9Q53qYlJLj   \n",
      "\n",
      "      sentiment polarity  \n",
      "0     -0.238095      NEG  \n",
      "1      0.000000      NEU  \n",
      "2      0.000000      NEU  \n",
      "3      0.000000      NEU  \n",
      "4      0.000000      NEU  \n",
      "...         ...      ...  \n",
      "1995   0.000000      NEU  \n",
      "1996   0.357143      POS  \n",
      "1997   0.500000      POS  \n",
      "1998  -0.162500      NEG  \n",
      "1999   0.000000      NEU  \n",
      "\n",
      "[2000 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "url_train = \"DataSets/group_datasets/corona_tweets_extracted_train.csv\"\n",
    "df_train = pd.read_csv(url_train)\n",
    "df_train2 = df_train[35000:37000].reset_index(drop=True)\n",
    "print(df_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  tweet_id                                            content  \\\n",
      "0      1240732695413395456  Any company that continues to deny their worke...   \n",
      "1      1240732695459696642  The same Tolu Ogunlesi that insisted that Mr J...   \n",
      "2      1240732695522664454  @pattonoswalt @AlanTudyk He can't pronounce co...   \n",
      "3      1240732695644291073                 Aqui risking the corona en el work   \n",
      "4      1240732695778324480  Day 5: We have rediscovered farming https://t....   \n",
      "...                    ...                                                ...   \n",
      "77373  1241039751454416897  Shaheen Bagh is still on.\\n\\nMosques are open....   \n",
      "77374  1241039751509049346  Over 50 Corona Virus cases in Maharashtra, hig...   \n",
      "77375  1241039751551082497  Living in England during the Corona virus whil...   \n",
      "77376  1241039751609815040  WHEN I HEARD KD HAD CORONA VIRUSðŸ˜” @nba YALL BE...   \n",
      "77377  1241039752024948736  Liberal choreographer returns to Bengaluru fro...   \n",
      "\n",
      "       sentiment polarity  \n",
      "0      -0.238095      NEG  \n",
      "1       0.000000      NEU  \n",
      "2       0.000000      NEU  \n",
      "3       0.000000      NEU  \n",
      "4       0.000000      NEU  \n",
      "...          ...      ...  \n",
      "77373   0.000000      NEU  \n",
      "77374   0.000000      NEU  \n",
      "77375   0.000000      NEU  \n",
      "77376   0.093750      POS  \n",
      "77377   0.000000      NEU  \n",
      "\n",
      "[77378 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "url_corona = \"DataSets/group_datasets/Covid300_ES_POLARITY100_classified4.csv\"\n",
    "df_corona = pd.read_csv(url_train)\n",
    "df_corona2 = df_corona[35000:370000].reset_index(drop=True)\n",
    "print(df_corona2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "df = pd.read_csv(url_test,encoding='utf-8')[35000:37000].reset_index(drop=True)\n",
    "dftest = pd.read_csv(url_test2,encoding='utf-8')[35000:37000].reset_index(drop=True)\n",
    "dftrain = pd.read_csv(url_train,encoding='utf-8')[35000:37000].reset_index(drop=True)\n",
    "dfcorona = pd.read_csv(url_corona,encoding='utf-8').reset_index(drop=True)\n",
    "#print(df)\n",
    "\n",
    "## Preproceso\n",
    "def frase(tw):\n",
    "    fr = TextBlob(tw)\n",
    "    return ' '.join(fr.words)\n",
    "\n",
    "\n",
    "def importantes(tw):\n",
    "    tlist = [a for a in tw.split() if a != 'user']\n",
    "    clean = ' '.join([t for t in tlist if re.match(r'[^\\W\\d]*$',t)]) # quita caracteres raros y digitos\n",
    "    clean = [w.lower() for w in clean.split() if w.lower() not in stopwords.words('english')]\n",
    "    return clean\n",
    "\n",
    "def quitadupl(twl):\n",
    "  \n",
    "    L = WordNetLemmatizer()\n",
    "    fr = []\n",
    "    for w in twl:\n",
    "        txw = L.lemmatize(w,'v')\n",
    "        fr.append(txw)\n",
    "    return ' '.join(fr)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar solo la primera vezya que  tarda bastante\n",
    "df['txt'] = df['content'].apply(lambda x : quitadupl(importantes(frase(x))))\n",
    "df.to_pickle('preproc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar solo la primera vezya que  tarda bastante\n",
    "dftest['txt'] = dftest['content'].apply(lambda x : quitadupl(importantes(frase(x))))\n",
    "dftest.to_pickle('preproc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar solo la primera vezya que  tarda bastante\n",
    "dftrain['txt'] = dftrain['content'].apply(lambda x : quitadupl(importantes(frase(x))))\n",
    "dftrain.to_pickle('preproc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejecutar solo la primera vezya que  tarda bastante\n",
    "dfcorona['txt'] = dfcorona['content'].apply(lambda x : quitadupl(importantes(frase(x))))\n",
    "df.to_pickle('preproc.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              tweet_id                                            content  \\\n",
      "0  1240732695413395456  Any company that continues to deny their worke...   \n",
      "1  1240732695459696642  The same Tolu Ogunlesi that insisted that Mr J...   \n",
      "2  1240732695522664454  @pattonoswalt @AlanTudyk He can't pronounce co...   \n",
      "3  1240732695644291073                 Aqui risking the corona en el work   \n",
      "4  1240732695778324480  Day 5: We have rediscovered farming https://t....   \n",
      "\n",
      "   sentiment polarity                                                txt  \n",
      "0  -0.238095      NEG  company continue deny workers pay sick leave d...  \n",
      "1   0.000000      NEU  tolu ogunlesi insist mr jonathan must hold pre...  \n",
      "2   0.000000      NEU         pattonoswalt alantudyk ca pronounce corona  \n",
      "3   0.000000      NEU                        aqui risk corona en el work  \n",
      "4   0.000000      NEU                          day rediscover farm https  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('preproc.pkl')\n",
    "print(df[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import xgboost as xgb\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "#Model Selection and Validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import CategoricalNB\n",
    "from nltk.classify import MaxentClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('bow',CountVectorizer(analyzer='word')),  # strings to token integer counts\n",
    "    ('tfidf', TfidfTransformer()),  # integer counts to weighted TF-IDF scores\n",
    "    ('classifier', MLPClassifier(solver='lbfgs', alpha=1e-5, hidden_layer_sizes=(5, 2), random_state=1))  \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.88      0.87      0.87       107\n",
      "         NEU       0.90      0.85      0.87       211\n",
      "         POS       0.75      0.85      0.80        82\n",
      "\n",
      "    accuracy                           0.86       400\n",
      "   macro avg       0.84      0.86      0.85       400\n",
      "weighted avg       0.86      0.86      0.86       400\n",
      "\n",
      "[[ 93  10   4]\n",
      " [ 12 180  19]\n",
      " [  1  11  70]]\n",
      "0.8575\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(df['txt'], df['polarity'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.83      0.87      0.85       103\n",
      "         NEU       0.91      0.83      0.86       208\n",
      "         POS       0.67      0.76      0.72        89\n",
      "\n",
      "    accuracy                           0.82       400\n",
      "   macro avg       0.80      0.82      0.81       400\n",
      "weighted avg       0.83      0.82      0.83       400\n",
      "\n",
      "[[ 90   5   8]\n",
      " [ 11 172  25]\n",
      " [  8  13  68]]\n",
      "0.825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34722\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:470: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(dftrain['txt'], dftrain['polarity'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "                       \n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.00      0.00      0.00         0\n",
      "         NEU       1.00      0.48      0.65       400\n",
      "         POS       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.48       400\n",
      "   macro avg       0.33      0.16      0.22       400\n",
      "weighted avg       1.00      0.48      0.65       400\n",
      "\n",
      "[[  0   0   0]\n",
      " [110 193  97]\n",
      " [  0   0   0]]\n",
      "0.4825\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34722\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(dftest['txt'], dftrain['polarity'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         NEG       0.61      0.48      0.54        29\n",
      "         NEU       0.77      0.65      0.71        37\n",
      "         POS       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.58        66\n",
      "   macro avg       0.46      0.38      0.41        66\n",
      "weighted avg       0.70      0.58      0.63        66\n",
      "\n",
      "[[14  7  8]\n",
      " [ 9 24  4]\n",
      " [ 0  0  0]]\n",
      "0.5757575757575758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34722\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "msg_train, msg_test, label_train, label_test = train_test_split(dfcorona['txt'], dfcorona['polarity'], test_size=0.2)\n",
    "pipeline.fit(msg_train,label_train)\n",
    "predictions = pipeline.predict(msg_test)\n",
    "print(classification_report(predictions,label_test))\n",
    "print(confusion_matrix(predictions,label_test))\n",
    "print(accuracy_score(predictions,label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
